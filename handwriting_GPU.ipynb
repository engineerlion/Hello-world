{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torchvision,torch\n",
    "import  torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist/',train=True,\n",
    "                                      download=True, transform= transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=4,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 <torch.utils.data.dataloader.DataLoader object at 0x7f06042c8890> \n",
      "\n",
      "02 <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f0570b56390>\n",
      "torch.Size([4, 1, 28, 28]) \n",
      "\n",
      "tensor([7, 0, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "#def imshow(img):\n",
    " #   img = img / 2 + 0.5     # unnormalize\n",
    "  #  npimg = img.numpy()\n",
    "   # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "print('01',trainloader,'\\n')\n",
    "dataiter = iter(trainloader)\n",
    "print('02',dataiter)\n",
    "\n",
    "\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape,'\\n')\n",
    "print(labels)\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 122)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(npimg.transpose((1,2,0)))\n",
    "    #plt.imshow(npimg)\n",
    "   # plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./mnist/',train=False,\n",
    "                                      download=True, transform= transforms.ToTensor())\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=4,shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(device)\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.577\n",
      "[1,  4000] loss: 0.338\n",
      "[1,  6000] loss: 0.209\n",
      "[1,  8000] loss: 0.167\n",
      "[1, 10000] loss: 0.141\n",
      "[1, 12000] loss: 0.116\n",
      "[1, 14000] loss: 0.102\n",
      "[2,  2000] loss: 0.087\n",
      "[2,  4000] loss: 0.085\n",
      "[2,  6000] loss: 0.081\n",
      "[2,  8000] loss: 0.068\n",
      "[2, 10000] loss: 0.081\n",
      "[2, 12000] loss: 0.068\n",
      "[2, 14000] loss: 0.071\n",
      "Finished Training\n",
      "training time is 53.128\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "       # print(outputs.shape,'\\n')\n",
    "       # print(labels.shape,'\\n')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            \n",
    "end = time.time()\n",
    "print('Finished Training')\n",
    "print('training time is %6.3f' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-test] *",
   "language": "python",
   "name": "conda-env-.conda-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
