{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torchvision,torch\n",
    "import  torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./mnist/',train=True,\n",
    "                                      download=True, transform= transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=4,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(trainloader):\n",
    "    b_x = x.shape\n",
    "    b_y = y.shape\n",
    "    print('Step: ', step, '| train_data的维度' ,b_x,'| train_target的维度',b_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 <torch.utils.data.dataloader.DataLoader object at 0x7f6ad380d650> \n",
      "\n",
      "02 <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f6ad382f810>\n",
      "torch.Size([4, 1, 28, 28]) \n",
      "\n",
      "tensor([8, 7, 7, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "#def imshow(img):\n",
    " #   img = img / 2 + 0.5     # unnormalize\n",
    "  #  npimg = img.numpy()\n",
    "   # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "print('01',trainloader,'\\n')\n",
    "dataiter = iter(trainloader)\n",
    "print('02',dataiter)\n",
    "\n",
    "\n",
    "\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape,'\\n')\n",
    "print(labels)\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 122)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(npimg.transpose((1,2,0)))\n",
    "    #plt.imshow(npimg)\n",
    "   # plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./mnist/',train=False,\n",
    "                                      download=True, transform= transforms.ToTensor())\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=4,shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(device)\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.712\n",
      "[1,  4000] loss: 0.351\n",
      "[1,  6000] loss: 0.179\n",
      "[1,  8000] loss: 0.145\n",
      "[1, 10000] loss: 0.133\n",
      "[1, 12000] loss: 0.104\n",
      "[1, 14000] loss: 0.116\n",
      "[2,  2000] loss: 0.085\n",
      "[2,  4000] loss: 0.084\n",
      "[2,  6000] loss: 0.074\n",
      "[2,  8000] loss: 0.076\n",
      "[2, 10000] loss: 0.063\n",
      "[2, 12000] loss: 0.071\n",
      "[2, 14000] loss: 0.058\n",
      "Finished Training\n",
      "training time is 112.592\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "       # print(outputs.shape,'\\n')\n",
    "       # print(labels.shape,'\\n')\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            \n",
    "end = time.time()\n",
    "print('Finished Training')\n",
    "print('training time is %6.3f' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cuda.is_available()\n",
    "print(a)\n",
    "\n",
    "ngpu= 1\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.rand(3,3).cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-test] *",
   "language": "python",
   "name": "conda-env-.conda-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
